# 数据挖掘基础知识

## KDD 知识发现步骤

1.数据清洗

2.数据转换

3.数据描述

4.特征选择

5.特征抽取

## 分类和聚类

 **分类：**是学会一个分类模型（称作分类器），该模型能把数据库中的数据项映射到给定类别中。分类技术是一种监督学习（Supervised Learning），即每个训练样本的数据对象已经有类标识，通过学习可以形成表达数据对象与类标识间对应的知识。

 **聚类：**聚类是把一组个体按照相似性归成若干类别，它的目的是使得属于同一类别的个体之间的差别尽可能的小，而不同类别上的个体间的差别尽可能的大。聚类属于无监督学习（Unsupervised Learning） ），当一组数据对象可以由一个概念（区别于其他的概念）来描述时，就形成一个簇（Cluster）。刻画了数据所蕴涵的类知识。

# 数据挖掘10大算法

## 1.C4.5 分类和决策树算法

![image-20210219105914207](images/image-20210219105914207.png)

![image-20210219105927398](images/image-20210219105927398.png)

## 2.k-means K-平均算法（解决聚类问题）

![image-20210219110525771](images/image-20210219110525771.png)

![image-20210219110540050](images/image-20210219110540050.png)

## 3.SVM支持向量机

## 4.APriori 关联规则频繁项集算法

![image-20210219102951237](images/image-20210219102951237.png)

来一道实际题目

![image-20210219103117768](images/image-20210219103117768.png)

### 计算频繁项集

1.首先我们需要生成k频繁项集，频繁项集是通过支持数来进行计算的

首先是L1，支持数就是这个东西出现的次数C1 = {(A,3),(B,5),(C,4),(D,3),(E,3)}

然后我们来进行判断，首先计算最小支持度 minisupport是40% * 5 = 2(我们有5个数据)，所以只要支持数大于2的计算是一个频繁项集

然后是L2，我们对前面的ABCDE进行组合，得到AB，AC，AD，AE，BC，BD，BE，CD，CE，统计其支持数，获取频繁项集，下面用黄色标出来的就是频繁项集了，其他的频繁项集同理

![image-20210219103719899](images/image-20210219103719899.png)

最后我们来计算最大频繁项集，最大频繁项集就是不被其他项包含的，比如ABC北ABCD包含，所以ABC不是最大频繁项集

### 生成关联规则

结果如下图所示，我们对最大频繁项集进行拆分，拆分成不同的小项，然后我们来计算支持度和信任度，

信任度等于 Lk/Xm-1 比如序号1（ABCD/ABC = 2/3 = 67%），支持度就是ABCD/总数 = 2/5 = 40%

然后关联规则就是前面的xm-1推出这个频繁项集剩下的部分，最后我们可以通过判断信任度来计算规则是否为强规则

![image-20210219104350755](images/image-20210219104350755.png)

## 5.EM最大期望算法

![image-20210219110319839](images/image-20210219110319839.png)

![image-20210219110338730](images/image-20210219110338730.png)

## 6.PageRank 网页排名

![image-20210219110927533](images/image-20210219110927533.png)

![image-20210219110936907](images/image-20210219110936907.png)

![image-20210219110950467](images/image-20210219110950467.png)

## 7.AdaBoost 自适应增强

## 8.KNN k-近邻算法

![image-20210219105210149](images/image-20210219105210149.png)

## 9.Naive Baye 朴素贝叶斯分类器

![image-20210219110125753](images/image-20210219110125753.png)

![image-20210219110138200](images/image-20210219110138200.png)

![image-20210219110151307](images/image-20210219110151307.png)

## 10.CART 分类回归树

# 其他算法

## ID3算法

![image-20210219105707122](images/image-20210219105707122.png)

![image-20210219105715104](images/image-20210219105715104.png)

![image-20210219105746770](images/image-20210219105746770.png)

